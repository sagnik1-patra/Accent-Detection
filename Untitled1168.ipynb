{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ef1aa45-fa72-4ac2-b805-e6a4b756f238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wavio\n",
      "  Downloading wavio-0.0.9-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wavio) (1.26.0)\n",
      "Downloading wavio-0.0.9-py3-none-any.whl (9.5 kB)\n",
      "Installing collected packages: wavio\n",
      "Successfully installed wavio-0.0.9\n"
     ]
    }
   ],
   "source": [
    "!pip install wavio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "992e7eb7-a3b4-479d-b248-3a2e678fb56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéôÔ∏è Recording 5 seconds... Speak now.\n",
      "‚úÖ Recording done.\n",
      "üîç Predicting accent...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "File not found: filepath=C:\\Users\\sagni\\Downloads\\Accent Detectection\\accent_model.keras. Please ensure the file is an accessible `.keras` zip file.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 98\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     97\u001b[39m     mp3_path = record_voice()\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m     \u001b[43mpredict_accent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmp3_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    100\u001b[39m     \u001b[38;5;66;03m# Cleanup temp files\u001b[39;00m\n\u001b[32m    101\u001b[39m     os.remove(TEMP_MP3)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 82\u001b[39m, in \u001b[36mpredict_accent\u001b[39m\u001b[34m(audio_path)\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict_accent\u001b[39m(audio_path):\n\u001b[32m     81\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müîç Predicting accent...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     model = \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m     le = get_label_encoder(DATASET_PATH)\n\u001b[32m     85\u001b[39m     wav_path = convert_mp3_to_wav(audio_path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:200\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(filepath, custom_objects, compile, safe_mode)\u001b[39m\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format.load_model_from_hdf5(\n\u001b[32m    197\u001b[39m         filepath, custom_objects=custom_objects, \u001b[38;5;28mcompile\u001b[39m=\u001b[38;5;28mcompile\u001b[39m\n\u001b[32m    198\u001b[39m     )\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath).endswith(\u001b[33m\"\u001b[39m\u001b[33m.keras\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    201\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    202\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    203\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mzip file.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    204\u001b[39m     )\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    206\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    207\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFile format not supported: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    208\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mKeras 3 only supports V3 `.keras` files and \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    217\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmight have a different name).\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    218\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: File not found: filepath=C:\\Users\\sagni\\Downloads\\Accent Detectection\\accent_model.keras. Please ensure the file is an accessible `.keras` zip file."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "import scipy.io.wavfile as wav\n",
    "from pydub import AudioSegment\n",
    "from keras.models import load_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import librosa\n",
    "import librosa.display\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Paths\n",
    "DATASET_PATH = r\"C:\\Users\\sagni\\Downloads\\Accent Detectection\\audio_data\"\n",
    "MODEL_PATH = r\"C:\\Users\\sagni\\Downloads\\Accent Detectection\\accent_model.keras\"\n",
    "TEMP_MP3 = \"temp_recording.mp3\"\n",
    "TEMP_WAV = \"temp_recording.wav\"\n",
    "\n",
    "# Constants\n",
    "DURATION = 5  # seconds\n",
    "SR = 22050\n",
    "FIXED_SHAPE = (2484, 33)\n",
    "\n",
    "# Rebuild Label Encoder\n",
    "def get_label_encoder(dataset_path):\n",
    "    labels = sorted([d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))])\n",
    "    le = LabelEncoder()\n",
    "    le.fit(labels)\n",
    "    return le\n",
    "\n",
    "# Record user voice and save as MP3\n",
    "def record_voice():\n",
    "    print(\"üéôÔ∏è Recording 5 seconds... Speak now.\")\n",
    "    recording = sd.rec(int(SR * DURATION), samplerate=SR, channels=1)\n",
    "    sd.wait()\n",
    "    wav.write(TEMP_WAV, SR, recording)\n",
    "    print(\"‚úÖ Recording done.\")\n",
    "    # Convert WAV to MP3\n",
    "    audio = AudioSegment.from_wav(TEMP_WAV)\n",
    "    audio.export(TEMP_MP3, format=\"mp3\")\n",
    "    return TEMP_MP3\n",
    "\n",
    "# Convert MP3 to WAV (if user provides MP3)\n",
    "def convert_mp3_to_wav(mp3_path):\n",
    "    sound = AudioSegment.from_mp3(mp3_path)\n",
    "    sound.export(TEMP_WAV, format=\"wav\")\n",
    "    return TEMP_WAV\n",
    "\n",
    "# Extract and pad features\n",
    "def extract_features(audio_path):\n",
    "    y, sr = librosa.load(audio_path, sr=SR)\n",
    "    \n",
    "    # Feature extraction\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    spec_contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "\n",
    "    # Align and stack features\n",
    "    min_frames = min(mfcc.shape[1], chroma.shape[1], spec_contrast.shape[1], zcr.shape[1])\n",
    "    mfcc = mfcc[:, :min_frames]\n",
    "    chroma = chroma[:, :min_frames]\n",
    "    spec_contrast = spec_contrast[:, :min_frames]\n",
    "    zcr = zcr[:, :min_frames]\n",
    "    \n",
    "    combined = np.vstack([mfcc, chroma, spec_contrast, zcr])\n",
    "    combined = combined.T  # Shape: (time_steps, features)\n",
    "\n",
    "    # Pad or truncate to match training shape\n",
    "    if combined.shape[0] < FIXED_SHAPE[0]:\n",
    "        pad_width = FIXED_SHAPE[0] - combined.shape[0]\n",
    "        combined = np.pad(combined, ((0, pad_width), (0, 0)), mode='constant')\n",
    "    else:\n",
    "        combined = combined[:FIXED_SHAPE[0], :]\n",
    "\n",
    "    return combined.astype(np.float32)\n",
    "\n",
    "# Predict Accent\n",
    "def predict_accent(audio_path):\n",
    "    print(\"üîç Predicting accent...\")\n",
    "    model = load_model(MODEL_PATH)\n",
    "    le = get_label_encoder(DATASET_PATH)\n",
    "\n",
    "    wav_path = convert_mp3_to_wav(audio_path)\n",
    "    features = extract_features(wav_path)\n",
    "    features = np.expand_dims(features, axis=0)\n",
    "\n",
    "    prediction = model.predict(features)\n",
    "    predicted_index = np.argmax(prediction)\n",
    "    predicted_accent = le.inverse_transform([predicted_index])[0]\n",
    "\n",
    "    print(f\"üó£Ô∏è Detected Accent: **{predicted_accent}**\")\n",
    "\n",
    "# Run\n",
    "if __name__ == \"__main__\":\n",
    "    mp3_path = record_voice()\n",
    "    predict_accent(mp3_path)\n",
    "\n",
    "    # Cleanup temp files\n",
    "    os.remove(TEMP_MP3)\n",
    "    os.remove(TEMP_WAV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf9360b-40ef-4359-9a9b-6eae5f135180",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (moviepy)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
